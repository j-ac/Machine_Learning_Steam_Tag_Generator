{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prereq libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pb\n",
    "import random\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Possibly useful TensorFlow and Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, CuDNNLSTM\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "# Read in dataset from csv files\n",
    "dataset = pb.read_csv('min_75_max5k_as_ids.csv')\n",
    "# data = np.genfromtxt('min_75_max5k_as_ids.csv', delimiter = ',', usecols=np.arange(0,1000))\n",
    "# data = [np.array(map(int, line.split())) for line in open('min_75_max5k_as_ids.csv')]\n",
    "# data[1]\n",
    "\n",
    "TRAINING_INPUT_FILE = \"min75_max5k_as_ids.csv\"\n",
    "\n",
    "TRUE_TAGS_OUTPUT_FILE = \"true_tags.csv\"\n",
    "PREDICTED_TAGS_OUTPUT_FILE = \"predicted_tags.csv\"\n",
    "RANDOM_GAME_OUTPUT_FILE = \"random_game_prediction.csv\"\n",
    "\n",
    "TRAINING_SPLIT = 0.2\n",
    "ALPHA = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functs import npFloatArray, load_data\n",
    "\n",
    "# load features and labels based on those present in the CSV files\n",
    "features = np.array(dataset.copy())\n",
    "\n",
    "# Load Data\n",
    "X_train, X_test, y_train, y_test = load_data(dataset, \n",
    "                                             TRAINING_SPLIT)\n",
    "\n",
    "# Double check X_train's shape\n",
    "print(\"X_train's Shape: \" + str(X_train.shape[0]))\n",
    "\n",
    "# Set up dataset for model fitting\n",
    "num_rows, num_cols = X_train.shape\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],\n",
    "                               1,\n",
    "                               X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],\n",
    "                             1,\n",
    "                             X_test.shape[1]))\n",
    "\n",
    "# Test code used for printing results\n",
    "# ========================================================\n",
    "# all_tests= []\n",
    "# all_results = []\n",
    "\n",
    "# random_game_index = np.random.randint(0, len(all_X))\n",
    "# random_game_description = all_X[random_game_index]\n",
    "# random_game_results = []\n",
    "# ========================================================\n",
    "\n",
    "# Test code for shape sanity checks\n",
    "# ========================================================\n",
    "# print(num_cols)\n",
    "# print(num_rows)\n",
    "# print(y_train.shape[1:][0])\n",
    "\n",
    "# print(random_game_index)\n",
    "# print(random_game_description.shape)\n",
    "# print(X_train.shape[1:])\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ConvNN model implementation using Keras Library\n",
    "\n",
    "# Create sequential model object\n",
    "model = Sequential()\n",
    "\n",
    "# First hidden layer using Convolution with window size 64 & RelU activation [64 nodes]\n",
    "model.add(Conv2D(num_cols, (3,3), input_shape =(X_train.shape[1:])))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Second  hidden layer using Convolution with RelU activation [64 nodes]\n",
    "model.add(Conv2D(num_cols,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Third hidden layer using fully conncted nodes for flattening [64 nodes]\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_cols))\n",
    "\n",
    "# Final output layer using softmax activation [10 nodes]\n",
    "model.add(Dense(131))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# optimizer used for compilation, 'Adam' refers to gradient descent method that \"adapts\" using first and second order moments\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 1e-3, decay = 1e-5)\n",
    "\n",
    "# Final compilation\n",
    "model.compile(loss = 'sparse_ctegorical_crossentropy', optimizer = opt, metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Model Fitting process, this is the last step\n",
    "# Note: Currently having issues with Tensor conversion causing this step to not accept training data\n",
    "model.fit(X_train, y_train, batch_size = 3, validation_data = (X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
