{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prereq libraries\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pb\n",
    "import random\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Possibly useful TensorFlow and Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, CuDNNLSTM\n",
    "from keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "# Read in dataset from csv files\n",
    "dataset = pb.read_csv('min_75_max5k_as_ids.csv')\n",
    "# data = np.genfromtxt('min_75_max5k_as_ids.csv', delimiter = ',', usecols=np.arange(0,1000))\n",
    "# data = [np.array(map(int, line.split())) for line in open('min_75_max5k_as_ids.csv')]\n",
    "# data[1]\n",
    "\n",
    "TRAINING_INPUT_FILE = \"min75_max5k_as_ids.csv\"\n",
    "\n",
    "TRUE_TAGS_OUTPUT_FILE = \"true_tags.csv\"\n",
    "PREDICTED_TAGS_OUTPUT_FILE = \"predicted_tags.csv\"\n",
    "RANDOM_GAME_OUTPUT_FILE = \"random_game_prediction.csv\"\n",
    "\n",
    "TRAINING_SPLIT = 0.2\n",
    "ALPHA = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Y Index: 130\n",
      "Max X Index: 3276\n",
      "X_train's Shape: 14270\n"
     ]
    }
   ],
   "source": [
    "from functs import npFloatArray, load_data\n",
    "\n",
    "# load features and labels based on those present in the CSV files\n",
    "features = np.array(dataset.copy())\n",
    "\n",
    "# Load Data\n",
    "X_train, X_test, y_train, y_test = load_data(dataset, \n",
    "                                             TRAINING_SPLIT)\n",
    "\n",
    "# Double check X_train's shape\n",
    "print(\"X_train's Shape: \" + str(X_train.shape[0]))\n",
    "\n",
    "# Set up dataset for model fitting\n",
    "num_rows, num_cols = X_train.shape\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],\n",
    "                               1,\n",
    "                               X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0],\n",
    "                             1,\n",
    "                             X_test.shape[1]))\n",
    "\n",
    "# Test code used for printing results\n",
    "# ========================================================\n",
    "# all_tests= []\n",
    "# all_results = []\n",
    "\n",
    "# random_game_index = np.random.randint(0, len(all_X))\n",
    "# random_game_description = all_X[random_game_index]\n",
    "# random_game_results = []\n",
    "# ========================================================\n",
    "\n",
    "# Test code for shape sanity checks\n",
    "# ========================================================\n",
    "# print(num_cols)\n",
    "# print(num_rows)\n",
    "# print(y_train.shape[1:][0])\n",
    "\n",
    "# print(random_game_index)\n",
    "# print(random_game_description.shape)\n",
    "# print(X_train.shape[1:])\n",
    "# ========================================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 1, 3277)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_29188\\4088746397.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# First hidden layer using Convolution with window size 64 & RelU activation [64 nodes]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_cols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_shape\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mActivation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Dev\\Anaconda\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Dev\\Anaconda\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32me:\\Dev\\Anaconda\\lib\\site-packages\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    248\u001b[0m             \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mndim\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin_ndim\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 250\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    251\u001b[0m                     \u001b[1;34mf'Input {input_index} of layer \"{layer_name}\" '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m                     \u001b[1;34m\"is incompatible with the layer: \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (None, 1, 3277)"
     ]
    }
   ],
   "source": [
    "# ConvNN model implementation using Keras Library\n",
    "\n",
    "# Create sequential model object\n",
    "model = Sequential()\n",
    "\n",
    "# First hidden layer using Convolution with window size 64 & RelU activation [3227 nodes]\n",
    "model.add(Conv2D(num_cols, (3,3), input_shape =(X_train.shape[1:])))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Second  hidden layer using Convolution with RelU activation [3227 nodes]\n",
    "model.add(Conv2D(num_cols,(3,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "# Third hidden layer using fully conncted nodes for flattening\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_cols))\n",
    "\n",
    "# Final output layer using softmax activation [131 nodes]\n",
    "model.add(Dense(131))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# optimizer used for compilation, 'Adam' refers to gradient descent method that \"adapts\" using first and second order moments\n",
    "opt = tf.keras.optimizers.Adam(learning_rate = 1e-3, decay = 1e-5)\n",
    "\n",
    "# Final compilation\n",
    "model.compile(loss = 'sparse_ctegorical_crossentropy', optimizer = opt, metrics = ['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.RootMeanSquaredError()])\n",
    "\n",
    "# Model Fitting process, this is the last step\n",
    "# Note: Currently having issues with Tensor conversion causing this step to not accept training data\n",
    "model.fit(X_train, y_train, batch_size = 3, validation_data = (X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
